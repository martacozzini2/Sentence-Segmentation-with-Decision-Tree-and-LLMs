{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Script for segmenting a corpus into sentences using spaCy\n",
        "#\n",
        "# Features:\n",
        "# - Loads a text corpus from file\n",
        "# - Splits the text into blocks using a pattern based on lines separated by ---\n",
        "# - For each block:\n",
        "#     - Replaces line breaks (\\n) with <seg> to indicate internal segments\n",
        "#     - Segments the text into sentences using the Italian spaCy model\n",
        "#     - Removes any <seg> tags at the beginning of sentences\n",
        "# - Saves all numbered sentences (one per line, with index) to an output file\n",
        "# - Automatically downloads the resulting file (for use in Google Colab)\n",
        "# ==========================================================\n",
        "\n",
        "\n",
        "# Download and import the Italian spaCy model\n",
        "!python -m spacy download it_core_news_sm\n",
        "\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "# Load the Italian spaCy language model\n",
        "nlp = spacy.load(\"it_core_news_sm\")\n",
        "\n",
        "# Functions\n",
        "\n",
        "# Reads the content of a text file\n",
        "def carica_testo(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        testo = f.read()\n",
        "    return testo\n",
        "\n",
        "# Removes <seg> at the beginning of sentences\n",
        "def rimuovi_seg_inizio_frase(frasi):\n",
        "    frasi_pulite = []\n",
        "    for frase in frasi:\n",
        "        frase_pulita = re.sub(r'^<seg>\\s*', '', frase)\n",
        "        frasi_pulite.append(frase_pulita)\n",
        "    return frasi_pulite\n",
        "\n",
        "# Segments the text into sentences using spaCy\n",
        "def segmenta_testo_spacy(testo):\n",
        "    paragrafi = testo.split(\"\\n\\n\")  # Splits into paragraphs\n",
        "    frasi = []\n",
        "\n",
        "    for p in paragrafi:\n",
        "        p = p.strip()\n",
        "        if not p:\n",
        "            continue\n",
        "        # Replaces \\n with <seg> to mark internal breaks\n",
        "        p = p.replace(\"\\n\", \" <seg> \")\n",
        "        doc = nlp(p)\n",
        "        # Extracts and cleans the segmented sentences\n",
        "        frasi.extend([sent.text.strip() for sent in doc.sents if sent.text.strip()])\n",
        "\n",
        "    # Removes <seg> if it appears at the beginning of the sentence\n",
        "    frasi = rimuovi_seg_inizio_frase(frasi)\n",
        "    return frasi\n",
        "\n",
        "# Splits the text into blocks and segments each block into sentences\n",
        "def segmenta_blocchi(testo):\n",
        "    blocchi = re.split(r\"-{3,} \\d+ .+?\\.txt -{3,}\", testo)  # Splits based on block pattern\n",
        "    blocchi = [b.strip() for b in blocchi if b.strip()]\n",
        "\n",
        "    frasi_totali = []\n",
        "    for blocco in blocchi:\n",
        "        frasi_blocco = segmenta_testo_spacy(blocco)\n",
        "        frasi_totali.extend(frasi_blocco)\n",
        "    return frasi_totali\n",
        "\n",
        "# Saves the numbered sentences to a file\n",
        "def salva_frasi_con_indice(frasi, output_path):\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, frase in enumerate(frasi, 1):\n",
        "            f.write(f\"{i}\\t{frase}\\n\")\n",
        "\n",
        "\n",
        "input_file = \"/content/corpus_dueparole.txt\"\n",
        "output_file = \"output_corpus_in_frasi.txt\"\n",
        "\n",
        "# Load the text, segment into sentences, and save\n",
        "testo = carica_testo(input_file)\n",
        "frasi = segmenta_blocchi(testo)\n",
        "salva_frasi_con_indice(frasi, output_file)\n",
        "\n",
        "# Download the segmented file\n",
        "from google.colab import files\n",
        "files.download(\"output_corpus_in_frasi.txt\")\n",
        "\n",
        "# From here, we manually remove the recipes"
      ],
      "metadata": {
        "id": "xRamGAERaSE2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}